import tensorflow as tf
import numpy as np
from utils.layers import conv2d, conv2d_bn
import math

def srcnn_ete(inputs, padding = 'VALID', name='SRCNN'):
    '''
    Built the PDCNN model.
    Args:
        inputs: down-sampled polarized images
        padding: padding mode of convolution
    Returns:
        X_hat: reconstructed polarized images
        S_para: Stokes parameters
        Grad: gradient images
        
    '''
#    keep_prob = tf.where(is_training, 0.2, 1.0)
    with tf.variable_scope(name):
        # conventional layers
        x_1 = conv2d(inputs, [4, 4], 96, activation=tf.nn.relu, padding=padding, name='conv_1')
        tf.add_to_collection('feature_maps', x_1)
        x_2 = conv2d(x_1, [3,3], 48, activation=tf.nn.relu, padding=padding, name='conv_2')
        tf.add_to_collection('feature_maps', x_2)

        x_3_1 = conv2d(x_2, [3, 3], 32, activation=tf.nn.relu, padding=padding, name='conv_3_1')
        tf.add_to_collection('feature_maps', x_3_1)
        s0 = conv2d(x_3_1, [5, 5], 1, activation=None, padding=padding, name='conv_4_1')

        x_3_2 = conv2d(x_2, [3, 3], 32, activation=tf.nn.relu, padding=padding, name='conv_3_2')
        tf.add_to_collection('feature_maps', x_3_2)
        dolp = conv2d(x_3_2, [5, 5], 1, activation=None, padding=padding, name='conv_4_2')

        x_3_3 = conv2d(x_2, [3, 3], 32, activation=tf.nn.relu, padding=padding, name='conv_3_3')
        tf.add_to_collection('feature_maps', x_3_3)
        aop = conv2d(x_3_3, [4, 4], 1, activation=None, padding=padding, name='conv_4_3')
        aop = tf.atan(aop) / 2. + math.pi / 4

    return s0, dolp, aop


def MAE_LOSS(s0_pred, s0_true, dolp_pred, dolp_true, aop_pred, aop_true):
    '''
    Define the mae loss function.
    '''
    loss = tf.reduce_mean(0.1*tf.abs(s0_true - s0_pred) + tf.abs(dolp_true - dolp_pred) + 0.05*tf.abs(aop_true - aop_pred))

    return loss

def smooth_loss(s0_pred, s0_true, dolp_pred, dolp_true, aop_pred, aop_true):
    '''
    Define the mae loss function.
    '''
    loss = 0.1*smooth_l1_loss(s0_true, s0_pred, 2) + smooth_l1_loss(dolp_true, dolp_pred, 2) + 0.01*smooth_l1_loss(aop_true, aop_pred, 2)

    return loss

def smooth_l1_loss(reg_true, reg_pred, sigma):
    '''

    :param reg_true: a tensor with shape (#object, 4)
    :param reg_pred: a tensor with shape (#object, 4)
    :param sigma:
    :return: smooth_l1 loss
    '''
    sigma = sigma**2
    thres = 1. / sigma
    diff = reg_true - reg_pred

    l1 = tf.abs(diff) - 0.5 / sigma
    l2 = sigma / 2. * tf.square(diff)
    loss = tf.reduce_mean(tf.where(tf.less(tf.abs(diff), thres), l2, l1))

    return loss

def LOSS(s0_pred, s0_true, dolp_pred, dolp_true, aop_pred, aop_true, max_value=math.pi/2.):
    '''
    Define the loss function.
    '''
    L, C, S, sl = ssim_loss(aop_true, aop_pred, mv=max_value)
    loss = tf.reduce_mean(tf.reduce_sum(0.1*tf.abs(s0_true - s0_pred) + tf.abs(dolp_true - dolp_pred) + 0.05*tf.abs(aop_true - aop_pred), axis=[1,2,3])) \
                          - 0.02*tf.log(C)
    return loss

def MSE_LOSS(s0_pred, s0_true, dolp_pred, dolp_true, aop_pred, aop_true, max_value=math.pi/2.):
    '''
    Define the loss function.
    '''
    L, C, S, sl = ssim_loss(aop_true, aop_pred, mv=max_value)
    loss = tf.reduce_mean(0.1*tf.square(s0_true - s0_pred) + tf.square(dolp_true - dolp_pred) + 0.032*tf.square(aop_true - aop_pred)) - 0.02*tf.log(C)
    return loss

def std_variance(x):
    '''
    Compute the std_variance.
    '''
    shape = tf.cast(tf.shape(x), dtype = tf.float32)
    var = tf.sqrt(tf.reduce_sum((x-tf.reduce_mean(x))**2) / (shape[0]*shape[1]*shape[2]*shape[3]-1))

    return var

def covariance(x, y):
    '''
    Compute the covariance.
    '''
    shape = tf.cast(tf.shape(x), dtype=tf.float32)
    covar = tf.reduce_sum((x-tf.reduce_mean(x))*(y-tf.reduce_mean(y))) / (shape[0]*shape[1]*shape[2]*shape[3]-1)

    return covar

def ssim_loss(x, y, mv, k1=0.01, k2=0.03):
    '''
    Define the SSIM loss.
    '''
    c1 = (k1*mv)**2.
    c2 = (k2*mv)**2.
    c3 = c2/2.

    x_mean = tf.reduce_mean(x)
    y_mean = tf.reduce_mean(y)
    x_std_var = std_variance(x)
    y_std_var = std_variance(y)
    xy_covar = covariance(x,y)

    L = (2*x_mean*y_mean+c1) / (x_mean**2+y_mean**2+c1)   #lightness metric
    C = (2*x_std_var*y_std_var+c2) / (x_std_var**2+y_std_var**2+c2)   #contrast metric
    S = (xy_covar+c3) / (x_std_var*y_std_var+c3)   #structure metric
    SSIM = L*C*S
    # SSIM = ((2*x_mean*y_mean+c1)*(2*xy_covar+c2))/((x_mean**2+y_mean**2+c1)*(x_std_var**2+y_std_var**2+c2))

    loss = 1-SSIM

    return L, C, S, loss
